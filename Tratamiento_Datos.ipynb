{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de Datamart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "\n",
    "#----------------------------------- Configura la conexión a SQL Server DataMart --------------------------------\n",
    "conn = pyodbc.connect(\n",
    "    'DRIVER={ODBC Driver 17 for SQL Server};'  # Asegúrate de tener el controlador adecuado\n",
    "    'SERVER=localhost\\SQLEXPRESS01;'                  # Reemplaza con el nombre de tu servidor\n",
    "    'DATABASE=datamart_importaciones_2;'           # Reemplaza con el nombre de tu base de datos\n",
    "    'Trusted_Connection=yes;'                           # Reemplaza con tu contraseña\n",
    ")\n",
    "cursor = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max_1\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3553: DtypeWarning: Columns (3,4,9) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"final_finalisimo_ahora_si.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data '0' does not match format '%Y%m%d' (match)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:509\u001b[0m, in \u001b[0;36m_to_datetime_with_format\u001b[1;34m(arg, orig_arg, name, tz, fmt, exact, errors, infer_datetime_format)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 509\u001b[0m     values, tz \u001b[38;5;241m=\u001b[39m conversion\u001b[38;5;241m.\u001b[39mdatetime_to_datetime64(arg)\n\u001b[0;32m    510\u001b[0m     dta \u001b[38;5;241m=\u001b[39m DatetimeArray(values, dtype\u001b[38;5;241m=\u001b[39mtz_to_dtype(tz))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\tslibs\\conversion.pyx:359\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.datetime_to_datetime64\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Unrecognized value type: <class 'int'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#df['FECH_INGSI'] = pd.to_datetime(df['FECH_INGSI'],format='%Y%m%d')\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFECH_LLEGA\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFECH_LLEGA\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:883\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m    881\u001b[0m             result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mtz_localize(tz)  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, ABCSeries):\n\u001b[1;32m--> 883\u001b[0m     cache_array \u001b[38;5;241m=\u001b[39m _maybe_cache(arg, \u001b[38;5;28mformat\u001b[39m, cache, convert_listlike)\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache_array\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m    885\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:195\u001b[0m, in \u001b[0;36m_maybe_cache\u001b[1;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[0;32m    193\u001b[0m unique_dates \u001b[38;5;241m=\u001b[39m unique(arg)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dates) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(arg):\n\u001b[1;32m--> 195\u001b[0m     cache_dates \u001b[38;5;241m=\u001b[39m convert_listlike(unique_dates, \u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m    196\u001b[0m     cache_array \u001b[38;5;241m=\u001b[39m Series(cache_dates, index\u001b[38;5;241m=\u001b[39munique_dates)\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;66;03m# GH#39882 and GH#35888 in case of None and NaT we get duplicates\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:393\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 393\u001b[0m     res \u001b[38;5;241m=\u001b[39m _to_datetime_with_format(\n\u001b[0;32m    394\u001b[0m         arg, orig_arg, name, tz, \u001b[38;5;28mformat\u001b[39m, exact, errors, infer_datetime_format\n\u001b[0;32m    395\u001b[0m     )\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    397\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:513\u001b[0m, in \u001b[0;36m_to_datetime_with_format\u001b[1;34m(arg, orig_arg, name, tz, fmt, exact, errors, infer_datetime_format)\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DatetimeIndex\u001b[38;5;241m.\u001b[39m_simple_new(dta, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m--> 513\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:500\u001b[0m, in \u001b[0;36m_to_datetime_with_format\u001b[1;34m(arg, orig_arg, name, tz, fmt, exact, errors, infer_datetime_format)\u001b[0m\n\u001b[0;32m    497\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m _box_as_indexlike(result, utc\u001b[38;5;241m=\u001b[39mutc, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;66;03m# fallback\u001b[39;00m\n\u001b[1;32m--> 500\u001b[0m     res \u001b[38;5;241m=\u001b[39m _array_strptime_with_fallback(\n\u001b[0;32m    501\u001b[0m         arg, name, tz, fmt, exact, errors, infer_datetime_format\n\u001b[0;32m    502\u001b[0m     )\n\u001b[0;32m    503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;66;03m# Fallback to try to convert datetime objects if timezone-aware\u001b[39;00m\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;66;03m#  datetime objects are found without passing `utc=True`\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:436\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, tz, fmt, exact, errors, infer_datetime_format)\u001b[0m\n\u001b[0;32m    433\u001b[0m utc \u001b[38;5;241m=\u001b[39m tz \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 436\u001b[0m     result, timezones \u001b[38;5;241m=\u001b[39m array_strptime(arg, fmt, exact\u001b[38;5;241m=\u001b[39mexact, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m fmt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m fmt:\n\u001b[0;32m    438\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _return_parsed_timezone_results(result, timezones, tz, name)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\tslibs\\strptime.pyx:150\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: time data '0' does not match format '%Y%m%d' (match)"
     ]
    }
   ],
   "source": [
    "df['FECH_INGSI'] = pd.to_datetime(df['FECH_INGSI'],format='%Y%m%d')\n",
    "df['FECH_LLEGA'] = pd.to_datetime(df['FECH_LLEGA'],format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODI_ADUAN</th>\n",
       "      <th>NUME_CORRE</th>\n",
       "      <th>FECH_INGSI</th>\n",
       "      <th>TIPO_DOCUM</th>\n",
       "      <th>LIBR_TRIBU</th>\n",
       "      <th>DNOMBRE</th>\n",
       "      <th>CODI_AGENT</th>\n",
       "      <th>FECH_LLEGA</th>\n",
       "      <th>VIA_TRANSP</th>\n",
       "      <th>EMPR_TRANS</th>\n",
       "      <th>...</th>\n",
       "      <th>Jurisdiccion_Almacen</th>\n",
       "      <th>Cpais</th>\n",
       "      <th>Dpais</th>\n",
       "      <th>Cpuerto</th>\n",
       "      <th>Dpuerto</th>\n",
       "      <th>Descripcion_Aduana</th>\n",
       "      <th>Clase_Bulto</th>\n",
       "      <th>Razon Social</th>\n",
       "      <th>Codigo</th>\n",
       "      <th>Estado_Mercancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>235</td>\n",
       "      <td>135859</td>\n",
       "      <td>2024-09-03</td>\n",
       "      <td>4</td>\n",
       "      <td>20606352825</td>\n",
       "      <td>2M DIESEL S.A.C.</td>\n",
       "      <td>14</td>\n",
       "      <td>20240825</td>\n",
       "      <td>4</td>\n",
       "      <td>UX</td>\n",
       "      <td>...</td>\n",
       "      <td>A NIVEL NACIONAL</td>\n",
       "      <td>TR</td>\n",
       "      <td>TURKEY</td>\n",
       "      <td>IST</td>\n",
       "      <td>ISTANBUL</td>\n",
       "      <td>AEREA Y POSTAL EX-IAAC</td>\n",
       "      <td>BULTOS                                        ...</td>\n",
       "      <td>AIR EUROPA LINEAS AEREAS S.A. SUCURSAL DEL PERU</td>\n",
       "      <td>10</td>\n",
       "      <td>NUEVO/BUENO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>235</td>\n",
       "      <td>135859</td>\n",
       "      <td>2024-09-03</td>\n",
       "      <td>4</td>\n",
       "      <td>20606352825</td>\n",
       "      <td>2M DIESEL S.A.C.</td>\n",
       "      <td>14</td>\n",
       "      <td>20240825</td>\n",
       "      <td>4</td>\n",
       "      <td>UX</td>\n",
       "      <td>...</td>\n",
       "      <td>A NIVEL NACIONAL</td>\n",
       "      <td>TR</td>\n",
       "      <td>TURKEY</td>\n",
       "      <td>IST</td>\n",
       "      <td>ISTANBUL</td>\n",
       "      <td>AEREA Y POSTAL EX-IAAC</td>\n",
       "      <td>BULTOS                                        ...</td>\n",
       "      <td>AIR EUROPA LINEAS AEREAS S.A. SUCURSAL DEL PERU</td>\n",
       "      <td>10</td>\n",
       "      <td>NUEVO/BUENO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>235</td>\n",
       "      <td>137787</td>\n",
       "      <td>2024-09-06</td>\n",
       "      <td>4</td>\n",
       "      <td>20503101913</td>\n",
       "      <td>A &amp; N PROYECTOS S.A.C. - A &amp; N S.A.C.</td>\n",
       "      <td>3728</td>\n",
       "      <td>20240907</td>\n",
       "      <td>4</td>\n",
       "      <td>AF</td>\n",
       "      <td>...</td>\n",
       "      <td>No mencionado</td>\n",
       "      <td>ES</td>\n",
       "      <td>SPAIN</td>\n",
       "      <td>BCN</td>\n",
       "      <td>BARCELONA</td>\n",
       "      <td>AEREA Y POSTAL EX-IAAC</td>\n",
       "      <td>BULTOS                                        ...</td>\n",
       "      <td>SOCIETE AIR FRANCE SUCURSAL EN EL PERU</td>\n",
       "      <td>10</td>\n",
       "      <td>NUEVO/BUENO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>235</td>\n",
       "      <td>137787</td>\n",
       "      <td>2024-09-06</td>\n",
       "      <td>4</td>\n",
       "      <td>20503101913</td>\n",
       "      <td>A &amp; N PROYECTOS S.A.C. - A &amp; N S.A.C.</td>\n",
       "      <td>3728</td>\n",
       "      <td>20240907</td>\n",
       "      <td>4</td>\n",
       "      <td>AF</td>\n",
       "      <td>...</td>\n",
       "      <td>No mencionado</td>\n",
       "      <td>ES</td>\n",
       "      <td>SPAIN</td>\n",
       "      <td>BCN</td>\n",
       "      <td>BARCELONA</td>\n",
       "      <td>AEREA Y POSTAL EX-IAAC</td>\n",
       "      <td>BULTOS                                        ...</td>\n",
       "      <td>SOCIETE AIR FRANCE SUCURSAL EN EL PERU</td>\n",
       "      <td>10</td>\n",
       "      <td>NUEVO/BUENO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>235</td>\n",
       "      <td>137787</td>\n",
       "      <td>2024-09-06</td>\n",
       "      <td>4</td>\n",
       "      <td>20503101913</td>\n",
       "      <td>A &amp; N PROYECTOS S.A.C. - A &amp; N S.A.C.</td>\n",
       "      <td>3728</td>\n",
       "      <td>20240907</td>\n",
       "      <td>4</td>\n",
       "      <td>AF</td>\n",
       "      <td>...</td>\n",
       "      <td>No mencionado</td>\n",
       "      <td>ES</td>\n",
       "      <td>SPAIN</td>\n",
       "      <td>BCN</td>\n",
       "      <td>BARCELONA</td>\n",
       "      <td>AEREA Y POSTAL EX-IAAC</td>\n",
       "      <td>BULTOS                                        ...</td>\n",
       "      <td>SOCIETE AIR FRANCE SUCURSAL EN EL PERU</td>\n",
       "      <td>10</td>\n",
       "      <td>NUEVO/BUENO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CODI_ADUAN  NUME_CORRE FECH_INGSI TIPO_DOCUM   LIBR_TRIBU  \\\n",
       "0         235      135859 2024-09-03          4  20606352825   \n",
       "1         235      135859 2024-09-03          4  20606352825   \n",
       "2         235      137787 2024-09-06          4  20503101913   \n",
       "3         235      137787 2024-09-06          4  20503101913   \n",
       "4         235      137787 2024-09-06          4  20503101913   \n",
       "\n",
       "                                 DNOMBRE  CODI_AGENT  FECH_LLEGA  VIA_TRANSP  \\\n",
       "0                       2M DIESEL S.A.C.          14    20240825           4   \n",
       "1                       2M DIESEL S.A.C.          14    20240825           4   \n",
       "2  A & N PROYECTOS S.A.C. - A & N S.A.C.        3728    20240907           4   \n",
       "3  A & N PROYECTOS S.A.C. - A & N S.A.C.        3728    20240907           4   \n",
       "4  A & N PROYECTOS S.A.C. - A & N S.A.C.        3728    20240907           4   \n",
       "\n",
       "  EMPR_TRANS  ...  Jurisdiccion_Almacen  Cpais   Dpais Cpuerto    Dpuerto  \\\n",
       "0         UX  ...      A NIVEL NACIONAL     TR  TURKEY     IST   ISTANBUL   \n",
       "1         UX  ...      A NIVEL NACIONAL     TR  TURKEY     IST   ISTANBUL   \n",
       "2         AF  ...         No mencionado     ES   SPAIN     BCN  BARCELONA   \n",
       "3         AF  ...         No mencionado     ES   SPAIN     BCN  BARCELONA   \n",
       "4         AF  ...         No mencionado     ES   SPAIN     BCN  BARCELONA   \n",
       "\n",
       "       Descripcion_Aduana                                        Clase_Bulto  \\\n",
       "0  AEREA Y POSTAL EX-IAAC  BULTOS                                        ...   \n",
       "1  AEREA Y POSTAL EX-IAAC  BULTOS                                        ...   \n",
       "2  AEREA Y POSTAL EX-IAAC  BULTOS                                        ...   \n",
       "3  AEREA Y POSTAL EX-IAAC  BULTOS                                        ...   \n",
       "4  AEREA Y POSTAL EX-IAAC  BULTOS                                        ...   \n",
       "\n",
       "                                      Razon Social  Codigo  Estado_Mercancia  \n",
       "0  AIR EUROPA LINEAS AEREAS S.A. SUCURSAL DEL PERU      10       NUEVO/BUENO  \n",
       "1  AIR EUROPA LINEAS AEREAS S.A. SUCURSAL DEL PERU      10       NUEVO/BUENO  \n",
       "2           SOCIETE AIR FRANCE SUCURSAL EN EL PERU      10       NUEVO/BUENO  \n",
       "3           SOCIETE AIR FRANCE SUCURSAL EN EL PERU      10       NUEVO/BUENO  \n",
       "4           SOCIETE AIR FRANCE SUCURSAL EN EL PERU      10       NUEVO/BUENO  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CODI_ADUAN', 'NUME_CORRE', 'FECH_INGSI', 'TIPO_DOCUM', 'LIBR_TRIBU',\n",
       "       'DNOMBRE', 'CODI_AGENT', 'FECH_LLEGA', 'VIA_TRANSP', 'EMPR_TRANS',\n",
       "       'CODI_ALMA', 'FECH_RECEP', 'PAIS_ORIGE', 'PAIS_ADQUI', 'PUER_EMBAR',\n",
       "       'FECH_EMBAR', 'NUME_SERIE', 'DESC_COMER', 'FLE_DOLAR', 'SEG_DOLAR',\n",
       "       'PESO_NETO', 'PESO_BRUTO', 'UNID_FIQTY', 'UNID_FIDES', 'QUNICOM',\n",
       "       'TUNICOM', 'SEST_MERCA', 'CANT_BULTO', 'CLASE', 'Razon_Social_Almacen',\n",
       "       'Jurisdiccion_Almacen', 'Cpais', 'Dpais', 'Cpuerto', 'Dpuerto',\n",
       "       'Descripcion_Aduana', 'Clase_Bulto', 'Razon Social', 'Codigo',\n",
       "       'Estado_Mercancia', 'TRANSPORTE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La máxima longitud en caracteres es: 90\n"
     ]
    }
   ],
   "source": [
    "max_longitud = df['DESC_COMER'].apply(lambda x: len(str(x))).max()\n",
    "print(f\"La máxima longitud en caracteres es: {max_longitud}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CANT_BULTO'] = df['CANT_BULTO'].round(2) \n",
    "df['PESO_NETO'] = df['PESO_NETO'].round(2) \n",
    "df['PESO_BRUTO'] = df['PESO_BRUTO'].round(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"final_finalisimo_ahora_si.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creacion de tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"\"\"\n",
    "IF OBJECT_ID('Dim_FechaPuerto', 'U') IS NULL\n",
    "    CREATE TABLE Dim_FechaPuerto (\n",
    "        id_FechaPuerto INT PRIMARY KEY,\n",
    "        Dia INT NULL,\n",
    "        Mes INT NULL,\n",
    "        Año INT NULL,\n",
    "        Trimestre INT NULL\n",
    "    );\n",
    "IF OBJECT_ID('Dim_FechaAduana', 'U') IS NULL\n",
    "    CREATE TABLE Dim_FechaAduana (\n",
    "        id_FechaAduana INT PRIMARY KEY,\n",
    "        Dia INT NULL,\n",
    "        Mes INT NULL,\n",
    "        Año INT NULL,\n",
    "        Trimestre INT NULL\n",
    "    );\n",
    "    \n",
    "IF OBJECT_ID('Dim_Bulto', 'U') IS NULL\n",
    "    CREATE TABLE Dim_Bulto (\n",
    "        id_bulto INT PRIMARY KEY,\n",
    "        Clase_bulto VARCHAR(70)\n",
    "    );    \n",
    "    \n",
    "    \n",
    "IF OBJECT_ID('Dim_RecintoAduanero', 'U') IS NULL\n",
    "    CREATE TABLE Dim_RecintoAduanero (\n",
    "        id_Almacen INT PRIMARY KEY,\n",
    "        RazonSocial VARCHAR(70),\n",
    "        Jurisdiccion VARCHAR(25)\n",
    "    );    \n",
    "    \n",
    "IF OBJECT_ID('Dim_EstadoMercaderia', 'U') IS NULL\n",
    "    CREATE TABLE Dim_EstadoMercaderia (\n",
    "        id_EstadoMercaderia INT PRIMARY KEY,\n",
    "        estado_mercaderia VARCHAR(25)\n",
    "    );    \n",
    "    \n",
    "    \n",
    "IF OBJECT_ID('Dim_TransEmp', 'U') IS NULL\n",
    "    CREATE TABLE Dim_TransEmp (\n",
    "        id_ETRANS INT PRIMARY KEY,\n",
    "        documento VARCHAR(12),\n",
    "        razon_social VARCHAR(60)\n",
    "    );    \n",
    "    \n",
    "IF OBJECT_ID('Dim_Aduana', 'U') IS NULL\n",
    "      CREATE TABLE Dim_Aduana (\n",
    "          id_Aduana INT PRIMARY KEY,\n",
    "          Descripcion VARCHAR(25)\n",
    "      );    \n",
    "        \n",
    "IF OBJECT_ID('Dim_Transporte', 'U') IS NULL\n",
    "    CREATE TABLE Dim_Transporte (\n",
    "        id_Transporte INT PRIMARY KEY,\n",
    "        transporte VARCHAR(10)\n",
    "    );    \n",
    "    \n",
    "\n",
    "IF OBJECT_ID('Dim_Puerto', 'U') IS NULL\n",
    "    CREATE TABLE Dim_Puerto (\n",
    "        id_Puerto INT PRIMARY KEY,\n",
    "        nombre_puerto VARCHAR(35),\n",
    "        nombre_pais VARCHAR(35)\n",
    "    );    \n",
    "    \n",
    "\n",
    "IF OBJECT_ID('Dim_Mercaderia', 'U') IS NULL\n",
    "    CREATE TABLE Dim_Mercaderia (\n",
    "        id_Mercaderia INT PRIMARY KEY,\n",
    "        mercaderia VARCHAR(90)\n",
    "    ); \n",
    "    \n",
    "IF OBJECT_ID('fact_importaciones', 'U') IS NULL\n",
    "    CREATE TABLE fact_importaciones(\n",
    "        id_FechaPuerto INT,\n",
    "        id_FechaAduana INT,\n",
    "        id_bulto INT,\n",
    "        id_Almacen INT,\n",
    "        id_EstadoMercaderia INT,\n",
    "        id_ETRANS INT,\n",
    "        id_Aduana INT,\n",
    "        id_Transporte INT,\n",
    "        id_Puerto INT,\n",
    "        id_Mercaderia INT,\n",
    "        PESO_NETO DECIMAL(10,2),\n",
    "        PESO_BRUTO DECIMAL(10,2),\n",
    "        CANTIDAD_BULTO INT,\n",
    "        CANTIDAD_MERCANCIA INT,\n",
    "        FOREIGN KEY (id_FechaPuerto) REFERENCES Dim_FechaPuerto(id_FechaPuerto),\n",
    "        FOREIGN KEY (id_FechaAduana) REFERENCES Dim_FechaAduana(id_FechaAduana),\n",
    "        FOREIGN KEY (id_bulto) REFERENCES Dim_Bulto(id_bulto),\n",
    "        FOREIGN KEY (id_Almacen) REFERENCES Dim_RecintoAduanero(id_Almacen),\n",
    "        FOREIGN KEY (id_EstadoMercaderia) REFERENCES Dim_EstadoMercaderia(id_EstadoMercaderia),\n",
    "        FOREIGN KEY (id_ETRANS) REFERENCES Dim_TransEmp(id_ETRANS),\n",
    "        FOREIGN KEY (id_Aduana) REFERENCES Dim_Aduana(id_Aduana),\n",
    "        FOREIGN KEY (id_Transporte) REFERENCES Dim_Transporte(id_Transporte),\n",
    "        FOREIGN KEY (id_Puerto) REFERENCES Dim_Puerto(id_Puerto),\n",
    "        FOREIGN KEY (id_Mercaderia) REFERENCES Dim_Mercaderia(id_Mercaderia)\n",
    "    );\n",
    "\"\"\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poblado de tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_unicos_df(df, columna):\n",
    "    \"\"\"Devuelve un DataFrame con los valores únicos de una columna en el DataFrame.\"\"\"\n",
    "    if columna in df.columns:\n",
    "        # Obtener los valores únicos y convertirlos en un DataFrame\n",
    "        return pd.DataFrame(df[columna].unique(), columns=[columna])\n",
    "    else:\n",
    "        raise ValueError(f\"La columna '{columna}' no existe en el DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Index([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCODI_ADUAN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNUME_CORRE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFECH_INGSI\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTIPO_DOCUM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLIBR_TRIBU\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      2\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDNOMBRE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCODI_AGENT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFECH_LLEGA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVIA_TRANSP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEMPR_TRANS\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCODI_ALMA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFECH_RECEP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPAIS_ORIGE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPAIS_ADQUI\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPUER_EMBAR\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFECH_EMBAR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNUME_SERIE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDESC_COMER\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFLE_DOLAR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSEG_DOLAR\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPESO_NETO\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPESO_BRUTO\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUNID_FIQTY\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUNID_FIDES\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQUNICOM\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      6\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTUNICOM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSEST_MERCA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCANT_BULTO\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCLASE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRazon_Social_Almacen\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      7\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJurisdiccion_Almacen\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCpais\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDpais\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCpuerto\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDpuerto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDescripcion_Aduana\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClase_Bulto\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRazon Social\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCodigo\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEstado_Mercancia\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRANSPORTE\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     10\u001b[0m       dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Index' is not defined"
     ]
    }
   ],
   "source": [
    "Index(['CODI_ADUAN', 'NUME_CORRE', 'FECH_INGSI', 'TIPO_DOCUM', 'LIBR_TRIBU',\r\n",
    "       'DNOMBRE', 'CODI_AGENT', 'FECH_LLEGA', 'VIA_TRANSP', 'EMPR_TRANS',\r\n",
    "       'CODI_ALMA', 'FECH_RECEP', 'PAIS_ORIGE', 'PAIS_ADQUI', 'PUER_EMBAR',\r\n",
    "       'FECH_EMBAR', 'NUME_SERIE', 'DESC_COMER', 'FLE_DOLAR', 'SEG_DOLAR',\r\n",
    "       'PESO_NETO', 'PESO_BRUTO', 'UNID_FIQTY', 'UNID_FIDES', 'QUNICOM',\r\n",
    "       'TUNICOM', 'SEST_MERCA', 'CANT_BULTO', 'CLASE', 'Razon_Social_Almacen',\r\n",
    "       'Jurisdiccion_Almacen', 'Cpais', 'Dpais', 'Cpuerto', 'Dpuerto',\r\n",
    "       'Descripcion_Aduana', 'Clase_Bulto', 'Razon Social', 'Codigo',\r\n",
    "       'Estado_Mercancia', 'TRANSPORTE'],\r\n",
    "      dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FechaPuerto=obtener_unicos_df(df,'FECH_INGSI')  # obtiene los nombres de distritos\n",
    "df_FechaAduana=obtener_unicos_df(df,'FECH_LLEGA')  # obtiene los nombres de distritos\n",
    "df_Aduana=obtener_unicos_df(df,'Descripcion_Aduana')  # obtiene los nombres de distritos\n",
    "df_RecintoAduanero=df[['Razon_Social_Almacen','Jurisdiccion_Almacen']].drop_duplicates(ignore_index=True)\n",
    "df_Mercaderia=obtener_unicos_df(df,'DESC_COMER')  # obtiene los nombres de distritos\n",
    "df_Puerto=df[['Dpuerto','Dpais']].drop_duplicates(ignore_index=True)\n",
    "df_Bulto=obtener_unicos_df(df,'Clase_Bulto')  # obtiene los nombres de distritos\n",
    "df_Transporte=obtener_unicos_df(df,'TRANSPORTE')  # obtiene los nombres de distritos\n",
    "df_EstadoMercaderia=obtener_unicos_df(df,'Estado_Mercancia')  # obtiene los nombres de distritos\n",
    "df_TransEmp=df[['LIBR_TRIBU','Razon Social']].drop_duplicates(ignore_index=True)\n",
    "\n",
    "\n",
    "# Función para agregar identificadores únicos\n",
    "def agregar_identificador(df, nombre_id):\n",
    "    df[nombre_id] = pd.Series(range(1, len(df) + 1))\n",
    "    return df\n",
    "\n",
    "# Aplicar a varios DataFrames\n",
    "df_FechaPuerto = agregar_identificador(df_FechaPuerto, 'id_fechaPuerto')\n",
    "df_FechaAduana = agregar_identificador(df_FechaAduana, 'id_fechaAduana')\n",
    "df_Aduana = agregar_identificador(df_Aduana, 'id_aduana')\n",
    "df_RecintoAduanero = agregar_identificador(df_RecintoAduanero, 'id_recinto')\n",
    "df_Mercaderia = agregar_identificador(df_Mercaderia, 'id_mercaderia')\n",
    "df_Puerto = agregar_identificador(df_Puerto, 'id_puerto')\n",
    "df_Bulto = agregar_identificador(df_Bulto, 'id_bulto')\n",
    "df_Transporte = agregar_identificador(df_Transporte, 'id_transporte')\n",
    "df_EstadoMercaderia = agregar_identificador(df_EstadoMercaderia, 'id_estadoMercaderia')\n",
    "df_TransEmp = agregar_identificador(df_TransEmp, 'id_transEmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_FechaPuerto['FECH_INGSI'] = pd.to_datetime(df_FechaPuerto['FECH_INGSI'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for index, row in df_FechaPuerto.iterrows():\n",
    "        cursor.execute(\n",
    "            \"INSERT INTO Dim_FechaPuerto (id_FechaPuerto, Dia, Mes, Año, Trimestre) VALUES (?, ?, ?, ?, ?)\",\n",
    "            row['id_fechaPuerto'], \n",
    "            row['FECH_INGSI'].day, \n",
    "            row['FECH_INGSI'].month, \n",
    "            row['FECH_INGSI'].year, \n",
    "            row['FECH_INGSI'].quarter\n",
    "        )\n",
    "    conn.commit()\n",
    "except Exception as e:\n",
    "    print(f\"Error al insertar registros en Dim_FechaPuerto: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al insertar registros en Dim_FechaPuerto: 'str' object has no attribute 'day'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "673it [00:00, 2791.37it/s]\n",
      "1237928it [02:54, 7075.98it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "try:\n",
    "    for index, row in df_FechaPuerto.iterrows():\n",
    "        cursor.execute(\n",
    "            \"INSERT INTO Dim_FechaPuerto (id_FechaPuerto, Dia, Mes, Año, Trimestre) VALUES (?, ?, ?, ?, ?)\",\n",
    "            row['id_fechaPuerto'], \n",
    "            row['FECH_INGSI'].day, \n",
    "            row['FECH_INGSI'].month, \n",
    "            row['FECH_INGSI'].year, \n",
    "            row['FECH_INGSI'].quarter\n",
    "        )\n",
    "    conn.commit()\n",
    "except Exception as e:\n",
    "    print(f\"Error al insertar registros en Dim_FechaPuerto: {e}\")\n",
    "try:\n",
    "    for index, row in tqdm(df_FechaAduana.iterrows()):\n",
    "        # Convertir a tipos nativos de Python (int o None)\n",
    "        id_fechaAduana = int(row['id_fechaAduana']) if not pd.isnull(row['id_fechaAduana']) else None\n",
    "        if row['FECH_LLEGA'] == 0:\n",
    "            dia, mes, año, trimestre = 0, 0, 0, 0\n",
    "        else:\n",
    "            fecha = pd.to_datetime(str(row['FECH_LLEGA']), format='%Y%m%d')\n",
    "            dia, mes, año, trimestre = fecha.day, fecha.month, fecha.year, fecha.quarter\n",
    "        \n",
    "        # Ejecutar la inserción\n",
    "        cursor.execute(\n",
    "            \"INSERT INTO Dim_FechaAduana (id_FechaAduana, Dia, Mes, Año, Trimestre) VALUES (?, ?, ?, ?, ?)\",\n",
    "            id_fechaAduana, dia, mes, año, trimestre\n",
    "        )\n",
    "    conn.commit()\n",
    "except Exception as e:\n",
    "    print(f\"Error al insertar registros en Dim_FechaAduana: {e}\")\n",
    "\n",
    "try:\n",
    "    for index, row in df_Bulto.iterrows():\n",
    "        cursor.execute(\n",
    "            \"INSERT INTO Dim_Bulto (id_bulto, Clase_bulto) VALUES (?, ?)\",\n",
    "            row['id_bulto'], \n",
    "            row['Clase_Bulto']\n",
    "        )\n",
    "    conn.commit()\n",
    "except Exception as e:\n",
    "    print(f\"Error al insertar registros en Dim_Bulto: {e}\")\n",
    "try:\n",
    "    for index, row in df_RecintoAduanero.iterrows():\n",
    "        cursor.execute(\n",
    "            \"INSERT INTO Dim_RecintoAduanero (id_Almacen, RazonSocial, Jurisdiccion) VALUES (?, ?, ?)\",\n",
    "            row['id_recinto'], \n",
    "            row['Razon_Social_Almacen'], \n",
    "            row['Jurisdiccion_Almacen']\n",
    "        )\n",
    "    conn.commit()\n",
    "except Exception as e:\n",
    "    print(f\"Error al insertar registros en Dim_RecintoAduanero: {e}\")\n",
    "try:\n",
    "    for index, row in df_EstadoMercaderia.iterrows():\n",
    "        cursor.execute(\n",
    "            \"INSERT INTO Dim_EstadoMercaderia (id_EstadoMercaderia, estado_mercaderia) VALUES (?, ?)\",\n",
    "            row['id_estadoMercaderia'], \n",
    "            row['Estado_Mercancia']\n",
    "        )\n",
    "    conn.commit()\n",
    "except Exception as e:\n",
    "    print(f\"Error al insertar registros en Dim_EstadoMercaderia: {e}\")\n",
    "try:\n",
    "    for index, row in df_TransEmp.iterrows():\n",
    "        cursor.execute(\n",
    "            \"INSERT INTO Dim_TransEmp (id_ETRANS, documento, razon_social) VALUES (?, ?, ?)\",\n",
    "            row['id_transEmp'], \n",
    "            row['LIBR_TRIBU'], \n",
    "            row['Razon Social']\n",
    "        )\n",
    "    conn.commit()\n",
    "except Exception as e:\n",
    "    print(f\"Error al insertar registros en Dim_TransEmp: {e}\")\n",
    "try:\n",
    "    for index, row in df_Aduana.iterrows():\n",
    "        cursor.execute(\n",
    "            \"INSERT INTO Dim_Aduana (id_Aduana, Descripcion) VALUES (?, ?)\",\n",
    "            row['id_aduana'], \n",
    "            row['Descripcion_Aduana']\n",
    "        )\n",
    "    conn.commit()\n",
    "except Exception as e:\n",
    "    print(f\"Error al insertar registros en Dim_Aduana: {e}\")\n",
    "try:\n",
    "    for index, row in df_Transporte.iterrows():\n",
    "        cursor.execute(\n",
    "            \"INSERT INTO Dim_Transporte (id_Transporte, transporte) VALUES (?, ?)\",\n",
    "            row['id_transporte'], \n",
    "            row['TRANSPORTE']\n",
    "        )\n",
    "    conn.commit()\n",
    "except Exception as e:\n",
    "    print(f\"Error al insertar registros en Dim_Transporte: {e}\")\n",
    "try:\n",
    "    for index, row in df_Puerto.iterrows():\n",
    "        cursor.execute(\n",
    "            \"INSERT INTO Dim_Puerto (id_Puerto, nombre_puerto, nombre_pais) VALUES (?, ?, ?)\",\n",
    "            row['id_puerto'], \n",
    "            row['Dpuerto'], \n",
    "            row['Dpais']\n",
    "        )\n",
    "    conn.commit()\n",
    "except Exception as e:\n",
    "    print(f\"Error al insertar registros en Dim_Puerto: {e}\")\n",
    "try:\n",
    "    for index, row in df_Mercaderia.iterrows():\n",
    "        cursor.execute(\n",
    "            \"INSERT INTO Dim_Mercaderia (id_Mercaderia, mercaderia) VALUES (?, ?)\",\n",
    "            row['id_mercaderia'], \n",
    "            row['DESC_COMER']\n",
    "        )\n",
    "    conn.commit()\n",
    "except Exception as e:\n",
    "    print(f\"Error al insertar registros en Dim_Mercaderia: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge con cada dimensión para obtener los IDs\n",
    "df = df.merge(df_FechaPuerto[['FECH_INGSI', 'id_fechaPuerto']], on='FECH_INGSI', how='left')\n",
    "df = df.merge(df_FechaAduana[['FECH_LLEGA', 'id_fechaAduana']], on='FECH_LLEGA', how='left')\n",
    "df = df.merge(df_Bulto[['Clase_Bulto', 'id_bulto']], on='Clase_Bulto', how='left')\n",
    "df = df.merge(df_RecintoAduanero[['Razon_Social_Almacen', 'Jurisdiccion_Almacen', 'id_recinto']],\n",
    "              on=['Razon_Social_Almacen', 'Jurisdiccion_Almacen'], how='left')\n",
    "df = df.merge(df_EstadoMercaderia[['Estado_Mercancia', 'id_estadoMercaderia']], on='Estado_Mercancia', how='left')\n",
    "df = df.merge(df_TransEmp[['LIBR_TRIBU', 'Razon Social', 'id_transEmp']],\n",
    "              on=['LIBR_TRIBU', 'Razon Social'], how='left')\n",
    "df = df.merge(df_Aduana[['Descripcion_Aduana', 'id_aduana']], on='Descripcion_Aduana', how='left')\n",
    "df = df.merge(df_Transporte[['TRANSPORTE', 'id_transporte']], on='TRANSPORTE', how='left')\n",
    "df = df.merge(df_Puerto[['Dpuerto', 'Dpais', 'id_puerto']], on=['Dpuerto', 'Dpais'], how='left')\n",
    "df = df.merge(df_Mercaderia[['DESC_COMER', 'id_mercaderia']], on='DESC_COMER', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FECH_INGSI'] = pd.to_datetime(df['FECH_INGSI'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insertando registros en fact_importaciones: 100%|██████████████████████████████████| 6676/6676 [14:26<00:00,  7.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos insertados correctamente en fact_importaciones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Preparar los datos para la inserción\n",
    "data_to_insert = df[[\n",
    "    'id_fechaPuerto', 'id_fechaAduana', 'id_bulto', 'id_recinto', 'id_estadoMercaderia',\n",
    "    'id_transEmp', 'id_aduana', 'id_transporte', 'id_puerto', 'id_mercaderia',\n",
    "    'PESO_NETO', 'PESO_BRUTO', 'CANT_BULTO', 'UNID_FIQTY'\n",
    "]].values.tolist()\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Dividir los datos en lotes (ejemplo: 1000 registros por lote)\n",
    "batch_size = 1000\n",
    "batches = [data_to_insert[i:i + batch_size] for i in range(0, len(data_to_insert), batch_size)]\n",
    "\n",
    "# Insertar los datos en lotes con barra de progreso\n",
    "try:\n",
    "    for batch in tqdm(batches, desc=\"Insertando registros en fact_importaciones\"):\n",
    "        cursor.executemany(\"\"\"\n",
    "            INSERT INTO fact_importaciones (\n",
    "                id_FechaPuerto, id_FechaAduana, id_bulto, id_Almacen, id_EstadoMercaderia, id_ETRANS, id_Aduana, id_Transporte, id_Puerto, id_Mercaderia,\n",
    "                PESO_NETO, PESO_BRUTO, CANTIDAD_BULTO, CANTIDAD_MERCANCIA\n",
    "            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\", batch)\n",
    "        conn.commit()\n",
    "    print(\"Datos insertados correctamente en fact_importaciones\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al insertar registros en fact_importaciones: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamiento de datos adicional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "\n",
    "#----------------------------------- Configura la conexión a SQL Server DataMart --------------------------------\n",
    "conn = pyodbc.connect(\n",
    "    'DRIVER={ODBC Driver 17 for SQL Server};'  # Asegúrate de tener el controlador adecuado\n",
    "    'SERVER=localhost\\SQLEXPRESS01;'                  # Reemplaza con el nombre de tu servidor\n",
    "    'DATABASE=datamart_importaciones_2;'           # Reemplaza con el nombre de tu base de datos\n",
    "    'Trusted_Connection=yes;'                           # Reemplaza con tu contraseña\n",
    ")\n",
    "cursor = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1239it [02:10,  9.48it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 24\u001b[0m\n\u001b[0;32m     19\u001b[0m id_transporte \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(df_Transporte\u001b[38;5;241m.\u001b[39mloc[df_Transporte[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRANSPORTE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRANSPORTE\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid_transporte\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     20\u001b[0m id_puerto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(df_Puerto\u001b[38;5;241m.\u001b[39mloc[\n\u001b[0;32m     21\u001b[0m     (df_Puerto[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDpuerto\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDpuerto\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m&\u001b[39m (df_Puerto[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDpais\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDpais\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid_puerto\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     23\u001b[0m ]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m---> 24\u001b[0m id_mercaderia \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(df_Mercaderia\u001b[38;5;241m.\u001b[39mloc[df_Mercaderia[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDESC_COMER\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDESC_COMER\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid_mercaderia\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Insertar en la tabla de hechos\u001b[39;00m\n\u001b[0;32m     27\u001b[0m cursor\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m     28\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m    INSERT INTO fact_importaciones (\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m     row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUNID_FIQTY\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     48\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\common.py:69\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     67\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, other)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:32\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cmp_method(other, operator\u001b[38;5;241m.\u001b[39meq)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:5502\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   5499\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   5501\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 5502\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mcomparison_op(lvalues, rvalues, op)\n\u001b[0;32m   5504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:284\u001b[0m, in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_object_dtype(lvalues\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 284\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    287\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:74\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[1;34m(op, x, y)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mscalar_compare(x\u001b[38;5;241m.\u001b[39mravel(), y, op)\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for index, row in tqdm(df.iterrows()):\n",
    "        # Obtener los IDs relacionados de las dimensiones\n",
    "        id_fechaPuerto = int(df_FechaPuerto.loc[df_FechaPuerto['FECH_INGSI'] == row['FECH_INGSI'], 'id_fechaPuerto'].values[0])\n",
    "        id_fechaAduana = int(df_FechaAduana.loc[df_FechaAduana['FECH_LLEGA'] == row['FECH_LLEGA'], 'id_fechaAduana'].values[0])\n",
    "        id_bulto = int(df_Bulto.loc[df_Bulto['Clase_Bulto'] == row['Clase_Bulto'], 'id_bulto'].values[0])\n",
    "        id_recinto = int(df_RecintoAduanero.loc[\n",
    "            (df_RecintoAduanero['Razon_Social_Almacen'] == row['Razon_Social_Almacen']) &\n",
    "            (df_RecintoAduanero['Jurisdiccion_Almacen'] == row['Jurisdiccion_Almacen']),\n",
    "            'id_recinto'\n",
    "        ].values[0])\n",
    "        id_estadoMercaderia = int(df_EstadoMercaderia.loc[df_EstadoMercaderia['Estado_Mercancia'] == row['Estado_Mercancia'], 'id_estadoMercaderia'].values[0])\n",
    "        id_transEmp = int(df_TransEmp.loc[\n",
    "            (df_TransEmp['LIBR_TRIBU'] == row['LIBR_TRIBU']) &\n",
    "            (df_TransEmp['Razon Social'] == row['Razon Social']),\n",
    "            'id_transEmp'\n",
    "        ].values[0])\n",
    "        id_aduana = int(df_Aduana.loc[df_Aduana['Descripcion_Aduana'] == row['Descripcion_Aduana'], 'id_aduana'].values[0])\n",
    "        id_transporte = int(df_Transporte.loc[df_Transporte['TRANSPORTE'] == row['TRANSPORTE'], 'id_transporte'].values[0])\n",
    "        id_puerto = int(df_Puerto.loc[\n",
    "            (df_Puerto['Dpuerto'] == row['Dpuerto']) & (df_Puerto['Dpais'] == row['Dpais']),\n",
    "            'id_puerto'\n",
    "        ].values[0])\n",
    "        id_mercaderia = int(df_Mercaderia.loc[df_Mercaderia['DESC_COMER'] == row['DESC_COMER'], 'id_mercaderia'].values[0])\n",
    "\n",
    "        # Insertar en la tabla de hechos\n",
    "        cursor.execute(\n",
    "            \"\"\"\n",
    "            INSERT INTO fact_importaciones (\n",
    "                id_FechaPuerto, id_FechaAduana, id_bulto, id_Almacen, id_EstadoMercaderia, id_ETRANS, id_Aduana, id_Transporte, id_Puerto, id_Mercaderia,\n",
    "                PESO_NETO, PESO_BRUTO, CANTIDAD_BULTO, CANTIDAD_MERCANCIA\n",
    "            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\",\n",
    "            id_fechaPuerto,\n",
    "            id_fechaAduana,\n",
    "            id_bulto,\n",
    "            id_recinto,\n",
    "            id_estadoMercaderia,\n",
    "            id_transEmp,\n",
    "            id_aduana,\n",
    "            id_transporte,\n",
    "            id_puerto,\n",
    "            id_mercaderia,\n",
    "            row['PESO_NETO'],\n",
    "            row['PESO_BRUTO'],\n",
    "            row['CANT_BULTO'],\n",
    "            row['UNID_FIQTY']\n",
    "        )\n",
    "    conn.commit()\n",
    "except Exception as e:\n",
    "    print(f\"Error al insertar registros en fact_importaciones: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CANT_BULTO'] = df['CANT_BULTO'].astype(int)\n",
    "df['UNID_FIQTY'] = df['UNID_FIQTY'].astype(int)\n",
    "df['PESO_NETO'] = df['PESO_NETO'].astype(float)\n",
    "df['PESO_BRUTO'] = df['PESO_BRUTO'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabla de ImportacionB (ImportacionB)\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "IF OBJECT_ID('ImportacionB', 'U') IS NULL\n",
    "BEGIN\n",
    "    CREATE TABLE ImportacionB (\n",
    "        CODI_ADUAN VARCHAR(3) NOT NULL, -- Código de aduana\n",
    "        ANO_PRESE VARCHAR(2) NOT NULL, -- Año de numeración de la DUA\n",
    "        NUME_CORRE VARCHAR(6) NOT NULL, -- Número de DUA\n",
    "        NUME_SECUP NUMERIC(4), -- Número de secuencia del proveedor\n",
    "        FECH_INGSI NUMERIC(8), -- Fecha de ingreso de la póliza\n",
    "        CODI_PROVE VARCHAR(10), -- Código del proveedor\n",
    "        NOMB_PROVE VARCHAR(60), -- Nombre del proveedor\n",
    "        PART_NANDI NUMERIC(10), -- Partida arancelaria\n",
    "        NUME_ITEM VARCHAR(4), -- Número de serie\n",
    "        VFOB_ITEM NUMERIC(17,6), -- FOB en dólares (FOB unitario x cantidad)\n",
    "        NOMB_COMER VARCHAR(30), -- Nombre comercial\n",
    "        MARC_COMER VARCHAR(25), -- Marca comercial\n",
    "        MODE_MERCD VARCHAR(30), -- Modelo\n",
    "        CANT_MERCD NUMERIC(17,6), -- Cantidad\n",
    "        UNID_MERCD VARCHAR(3), -- Unidad de medida\n",
    "        CARA_TIPO VARCHAR(90), -- Característica del producto\n",
    "        PAIS_ORIGE VARCHAR(2), -- País de origen\n",
    "        ARO_ANO VARCHAR(4), -- Año de producción\n",
    "        ESTA_MERCD VARCHAR(2), -- Estado del producto\n",
    "        VFOB_UNITA NUMERIC(17,6) -- FOB unitario\n",
    "    );\n",
    "END\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabla de Exportacion (Exportaciones)\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "IF OBJECT_ID('Exportaciones', 'U') IS NULL\n",
    "BEGIN\n",
    "    CREATE TABLE Exportaciones (\n",
    "        CADU VARCHAR(3) NOT NULL, -- Código de aduana\n",
    "        FANO VARCHAR(4) NOT NULL, -- Fecha de numeración de la orden de embarque\n",
    "        NDCL VARCHAR(6) NOT NULL, -- Número de orden de embarque\n",
    "        FNUM NUMERIC(8), -- Fecha de numeración de la orden de embarque\n",
    "        FEMB NUMERIC(8), -- Fecha de embarque\n",
    "        FECH_RECEP NUMERIC(8), -- Fecha de recepción de la declaración\n",
    "        NDCLREG VARCHAR(6) NOT NULL, -- Número de la declaración de exportación\n",
    "        FREG NUMERIC, -- Fecha de regularización\n",
    "        FANOREG VARCHAR(4), -- Año de regularización de exportación\n",
    "        CAGE VARCHAR(4), -- Código de agente de aduana\n",
    "        TDOC VARCHAR(1), -- Tipo de documento del exportador\n",
    "        NDOC VARCHAR(11), -- Número de documento del exportador\n",
    "        DNOMBRE VARCHAR(40), -- Razón social del exportador\n",
    "        CPAIDES VARCHAR(3), -- Código de país de destino\n",
    "        CPUEDES VARCHAR(6), -- Código del puerto de destino\n",
    "        CVIATRA VARCHAR(1), -- Código de la vía de transporte\n",
    "        CUNITRA VARCHAR(1), -- Código de unidad de transporte\n",
    "        CEMPTRA VARCHAR(4), -- Código de empresa de transporte\n",
    "        DMAT VARCHAR(30), -- Matrícula de la nave\n",
    "        NCON VARCHAR(20), -- Número de conocimiento\n",
    "        CENTFIN VARCHAR(3), -- Código de entidad financiera\n",
    "        CALM VARCHAR(4), -- Código de almacén\n",
    "        DNOMPRO VARCHAR(60), -- Nombre del proveedor\n",
    "        DDIRPRO VARCHAR(80), -- Dirección del proveedor\n",
    "        DK VARCHAR(1), -- Indicador de teledespacho para O.E.\n",
    "        DK2 VARCHAR(1), -- Indicador de teledespacho para DUE\n",
    "        NSER VARCHAR(4) NOT NULL, -- Número de serie\n",
    "        PART_NANDI NUMERIC(10), -- Código de la partida nandina\n",
    "        DCOM VARCHAR(100), -- Descripción comercial\n",
    "        DMER2 VARCHAR(100), -- Descripción comercial\n",
    "        DMER3 VARCHAR(100), -- Descripción comercial\n",
    "        DMER4 VARCHAR(100), -- Descripción comercial\n",
    "        DMER5 VARCHAR(100), -- Descripción comercial\n",
    "        VFOBSERDOL NUMERIC(11,3), -- Valor FOB de la serie\n",
    "        VPESNET NUMERIC(14,3), -- Peso neto de la serie\n",
    "        VPESBRU NUMERIC(14,3), -- Peso bruto de la serie\n",
    "        QUNIFIS NUMERIC(14,3), -- Cantidad exportada\n",
    "        TUNIFIS VARCHAR(10), -- Unidad de medida\n",
    "        QUNICOM NUMERIC(14,3), -- Cantidad de unidad comercial\n",
    "        TUNICOM VARCHAR(3), -- Tipo de unidad comercial\n",
    "        UBIGEO VARCHAR(6) -- Código de ubicación geográfica\n",
    "    );\n",
    "END\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las siguientes son tablas que contienen los recursos para algunas abreviaciones (paises, puertos, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tablas adicionales \n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "IF OBJECT_ID('exp', 'U') IS NULL\n",
    "BEGIN\n",
    "    CREATE TABLE exp (\n",
    "        CODI_ADUAN VARCHAR(3) NOT NULL,\n",
    "        ANO_PRESE VARCHAR(2) NOT NULL,\n",
    "        NUME_CORRE VARCHAR(6) NOT NULL,\n",
    "        FECH_INGSI NUMERIC(8),\n",
    "        TIPO_DOCUM VARCHAR(1),\n",
    "        LIBR_TRIBU VARCHAR(11),\n",
    "    );\n",
    "END\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inserción de información"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImportacionesA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero realizaremos un pre procesamiento de la información breve, Luego el llenado de las tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos de los archivos ma e ImportacionA (mismo contenido)\n",
    "df_ma = pd.read_csv('ImportacionA.csv',encoding='utf-8', sep=';')\n",
    "df_mam = pd.read_csv('mam.csv',encoding='utf-8', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7152794, 58)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unimos ambas tablas en una unica de importaciones \n",
    "df_importaciones=pd.concat([df_ma,df_mam],axis=0)\n",
    "df_importaciones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Campos con nan\n",
      "DNOMBRE 6\n",
      "EMPR_TRANS 610774\n",
      "BANC_CANCE 2754908\n",
      "CODI_ENFIN 5297838\n",
      "PAIS_ORIGE 3\n",
      "PUER_EMBAR 576\n",
      "DESC_MATCO 389720\n",
      "DESC_USOAP 681832\n",
      "DESC_FOPRE 40817\n",
      "DESC_OTROS 1609172\n",
      "IMPR_RELIQ 6117348\n"
     ]
    }
   ],
   "source": [
    "print(\"Campos con nan\")\n",
    "for c in df_importaciones.columns:\n",
    "    x=sum(df_importaciones[c].isna())\n",
    "    if x!=0:\n",
    "        print(c, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must specify a fill 'value' or 'method'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Eliminamos duplicados y reemplazamos nan (ocasionan problemas al momento de subir la base)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m df_importaciones\u001b[38;5;241m=\u001b[39mdf_importaciones\u001b[38;5;241m.\u001b[39mdrop_duplicates()\n\u001b[1;32m----> 3\u001b[0m df_importaciones\u001b[38;5;241m=\u001b[39mdf_importaciones\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5176\u001b[0m, in \u001b[0;36mDataFrame.fillna\u001b[1;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[0;32m   5165\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   5166\u001b[0m \u001b[38;5;129m@doc\u001b[39m(NDFrame\u001b[38;5;241m.\u001b[39mfillna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_shared_doc_kwargs)\n\u001b[0;32m   5167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfillna\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5174\u001b[0m     downcast\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5175\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 5176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfillna(\n\u001b[0;32m   5177\u001b[0m         value\u001b[38;5;241m=\u001b[39mvalue,\n\u001b[0;32m   5178\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m   5179\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5180\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5181\u001b[0m         limit\u001b[38;5;241m=\u001b[39mlimit,\n\u001b[0;32m   5182\u001b[0m         downcast\u001b[38;5;241m=\u001b[39mdowncast,\n\u001b[0;32m   5183\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6313\u001b[0m, in \u001b[0;36mNDFrame.fillna\u001b[1;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[0;32m   6205\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6206\u001b[0m \u001b[38;5;124;03mFill NA/NaN values using the specified method.\u001b[39;00m\n\u001b[0;32m   6207\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6310\u001b[0m \u001b[38;5;124;03m3   0.0 3.0 0.0 4\u001b[39;00m\n\u001b[0;32m   6311\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6312\u001b[0m inplace \u001b[38;5;241m=\u001b[39m validate_bool_kwarg(inplace, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minplace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 6313\u001b[0m value, method \u001b[38;5;241m=\u001b[39m validate_fillna_kwargs(value, method)\n\u001b[0;32m   6315\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m   6317\u001b[0m \u001b[38;5;66;03m# set the default here, so functions examining the signaure\u001b[39;00m\n\u001b[0;32m   6318\u001b[0m \u001b[38;5;66;03m# can detect if something was set (e.g. in groupby) (GH9221)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_validators.py:370\u001b[0m, in \u001b[0;36mvalidate_fillna_kwargs\u001b[1;34m(value, method, validate_scalar_dict_value)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clean_fill_method\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 370\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust specify a fill \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    372\u001b[0m     method \u001b[38;5;241m=\u001b[39m clean_fill_method(method)\n",
      "\u001b[1;31mValueError\u001b[0m: Must specify a fill 'value' or 'method'."
     ]
    }
   ],
   "source": [
    "# Eliminamos duplicados y reemplazamos nan (ocasionan problemas al momento de subir la base)\n",
    "df_importaciones=df_importaciones.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_importaciones = df_importaciones.where(pd.notnull(df_importaciones), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_almacen = pd.read_fwf('RecintAduaner.txt', widths=[7, 72, 50, 30, 15, 50, 10, 10])\n",
    "df_almacen.drop_duplicates(subset=\"Codigo\",inplace=True)\n",
    "df_aver = pd.merge(df_importaciones, df_almacen[['Codigo','Razon Social',\"Jurisdiccion\"]], right_on=\"Codigo\",left_on=\"CODI_ALMA\", how=\"left\")\n",
    "df_aver['Razon Social'] = df_aver['Razon Social'].fillna('No mencionado')\n",
    "df_aver['Codigo'] = df_aver['Codigo'].fillna(10000)\n",
    "df_aver['CODI_ALMA'] = df_aver['Codigo']\n",
    "df_aver['Jurisdiccion'] = df_aver['Jurisdiccion'].fillna(\"No mencionado\")\n",
    "df_aver.drop(columns='Codigo',inplace=True)\n",
    "df_aver.rename(columns={\"Razon Social\":\"Razon_Social_Almacen\",\"Jurisdiccion\":\"Jurisdiccion_Almacen\"})\n",
    "df_almacen.loc[581] = [10000,\"No mencionado\",\"No mencionado\",0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aver.to_csv(\"pasito.csv\",index=False,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max_1\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3553: DtypeWarning: Columns (4,5,10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_aver = pd.read_csv(\"pasito.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_puerto = pd.read_fwf(\"Puertos.txt\", widths=[6, 50, 7, 51, 15, 50, 10, 10,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_aver = pd.merge(df_aver, df_puerto[['Cpais','Dpais','Cpuerto','Dpuerto',\"Codigo_completo\"]], how='left', left_on='PUER_EMBAR', right_on='Codigo_completo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aver.drop(columns='PUER_EMBAR_3D',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_puerto['Codigo_completo'] = df_puerto['Cpais'] + df_puerto['Cpuerto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_aver['Cpais'] = df_aver['Cpais'].fillna(0)\n",
    "df_aver['Dpais'] = df_aver['Dpais'].fillna(\"No mencionado\")\n",
    "df_aver['Cpuerto'] = df_aver['Cpuerto'].fillna(0)\n",
    "df_aver['Dpuerto'] = df_aver['Dpuerto'].fillna(\"No mencionado\")\n",
    "df_aver['Codigo_completo'] = df_aver['Codigo_completo'].fillna(0)\n",
    "df_aver['PUER_EMBAR'] = df_aver['Codigo_completo']\n",
    "df_aver.drop(columns='Codigo_completo',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_puerto.loc[35108] = [0,\"No mencionado\",0,\"No mencionado\",0,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_backup = df_aver.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aduanas = pd.read_fwf(\"Aduanas.txt\", widths=[7, 71, 7, 51, 15, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aver = pd.merge(df_aver, df_aduanas[[\"Codigo\",\"Descripcion\"]], how='left', left_on='CODI_ADUAN', right_on='Codigo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aver.drop(columns='Codigo',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aver.rename(columns={'Descripcion':\"Descripcion_Aduana\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max_1\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3553: DtypeWarning: Columns (4,5,10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df_aver = pd.read_csv(\"mergeado.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CAJ', 'CRT', 'BUL', 'BOB', 'Z1', 'PK', 'PAL', 'PQT', 'SAC', 'BLS',\n",
       "       'FAR', 'GRN', 'VEI', 'PZS', 'CL', 'CS', 'BG', 'RLL', 'CT', 'DR',\n",
       "       'CTN', 'TAM', 'BN', 'LOT', 'BL', 'HUA', 'UNI', 'SKI', 'BX', 'BE',\n",
       "       'RL', 'JC', 'CIL', 'KGS', 'RO', 'BAL', 'PL', 'CNT', 'BRR', 'CR',\n",
       "       'BU', 'TNM', 'TK', 'BOT', 'CJ', 'JAB', 'KG', 'JGS', 'LAT', 'BI',\n",
       "       'ATD', 'BLL', 'BID', 'FR', 'EST', 'CU', 'BS', 'TY', 'ST', 'CA',\n",
       "       'BD', 'RT', 'ESQ', 'PI', 'BA', 'GB', 'PA', 'GAL', 'JY', 'PAR',\n",
       "       'PZ'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aver['CLASE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bulto = pd.read_fwf(\"UnidMercancia.txt\",widths=[7, 63, 7, 51, 15, 50])\n",
    "df_bulto = df_bulto[['Codigo','Descripcion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aver = pd.merge(df_aver, df_bulto, how='left', left_on='CLASE', right_on='Codigo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aver.rename(columns={'Descripcion':'Clase_Bulto'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aver.to_csv(\"df_final.csv\",index=False,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max_1\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3553: DtypeWarning: Columns (4,5,10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df_aver = pd.read_csv(\"df_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas con valores nulos:\n",
      "['DNOMBRE', 'PAIS_ORIGE']\n"
     ]
    }
   ],
   "source": [
    "columnas_con_na = df_final.columns[df_final.isnull().any()].tolist()\n",
    "print(\"Columnas con valores nulos:\")\n",
    "print(columnas_con_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 20, 12, 14, 28, 22, 99, 16, 26, 17, 27, 24], dtype=int64)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['SEST_MERCA'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.drop(columns=['DESC_MATCO','DESC_USOAP','DESC_FOPRE','DESC_OTROS'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"df_recontrafinal.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1505953"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['DESC_OTROS'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.drop(columns='Codigo',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CODI_ADUAN', 'NUME_CORRE', 'FECH_INGSI', 'TIPO_DOCUM', 'LIBR_TRIBU',\n",
       "       'DNOMBRE', 'CODI_AGENT', 'FECH_LLEGA', 'VIA_TRANSP', 'EMPR_TRANS',\n",
       "       'CODI_ALMA', 'FECH_RECEP', 'PAIS_ORIGE', 'PAIS_ADQUI', 'PUER_EMBAR',\n",
       "       'FECH_EMBAR', 'NUME_SERIE', 'DESC_COMER', 'DESC_MATCO', 'DESC_USOAP',\n",
       "       'DESC_FOPRE', 'DESC_OTROS', 'FLE_DOLAR', 'SEG_DOLAR', 'PESO_NETO',\n",
       "       'PESO_BRUTO', 'UNID_FIQTY', 'UNID_FIDES', 'QUNICOM', 'TUNICOM',\n",
       "       'SEST_MERCA', 'CANT_BULTO', 'CLASE', 'Razon_Social_Almacen',\n",
       "       'Jurisdiccion_Almacen', 'Cpais', 'Dpais', 'Cpuerto', 'Dpuerto',\n",
       "       'Descripcion_Aduana', 'Clase_Bulto', 'Razon Social'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mercancia = pd.read_fwf(\"EstMercancia.txt\",widths=[8,63,10,10,10,10])\n",
    "df_mercancia = df_mercancia[['Codigo','Descripcion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CODI_ADUAN', 'NUME_CORRE', 'FECH_INGSI', 'TIPO_DOCUM', 'LIBR_TRIBU',\n",
       "       'DNOMBRE', 'CODI_AGENT', 'FECH_LLEGA', 'VIA_TRANSP', 'EMPR_TRANS',\n",
       "       'CODI_ALMA', 'FECH_RECEP', 'PAIS_ORIGE', 'PAIS_ADQUI', 'PUER_EMBAR',\n",
       "       'FECH_EMBAR', 'NUME_SERIE', 'DESC_COMER', 'DESC_MATCO', 'DESC_USOAP',\n",
       "       'DESC_FOPRE', 'DESC_OTROS', 'FLE_DOLAR', 'SEG_DOLAR', 'PESO_NETO',\n",
       "       'PESO_BRUTO', 'UNID_FIQTY', 'UNID_FIDES', 'QUNICOM', 'TUNICOM',\n",
       "       'SEST_MERCA', 'CANT_BULTO', 'CLASE', 'Razon_Social_Almacen',\n",
       "       'Jurisdiccion_Almacen', 'Cpais', 'Dpais', 'Cpuerto', 'Dpuerto',\n",
       "       'Descripcion_Aduana', 'Clase_Bulto', 'Razon Social'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final = pd.merge(df_final,df_mercancia,left_on=\"SEST_MERCA\",right_on='Codigo',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.rename(columns={'Descripcion':'Estado_Mercancia'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODI_ADUAN</th>\n",
       "      <th>NUME_CORRE</th>\n",
       "      <th>FECH_INGSI</th>\n",
       "      <th>TIPO_DOCUM</th>\n",
       "      <th>LIBR_TRIBU</th>\n",
       "      <th>DNOMBRE</th>\n",
       "      <th>CODI_AGENT</th>\n",
       "      <th>FECH_LLEGA</th>\n",
       "      <th>VIA_TRANSP</th>\n",
       "      <th>EMPR_TRANS</th>\n",
       "      <th>...</th>\n",
       "      <th>Jurisdiccion_Almacen</th>\n",
       "      <th>Cpais</th>\n",
       "      <th>Dpais</th>\n",
       "      <th>Cpuerto</th>\n",
       "      <th>Dpuerto</th>\n",
       "      <th>Descripcion_Aduana</th>\n",
       "      <th>Clase_Bulto</th>\n",
       "      <th>Razon Social</th>\n",
       "      <th>Codigo</th>\n",
       "      <th>Estado_Mercancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>235</td>\n",
       "      <td>135859</td>\n",
       "      <td>20240903</td>\n",
       "      <td>4</td>\n",
       "      <td>20606352825</td>\n",
       "      <td>2M DIESEL S.A.C.</td>\n",
       "      <td>14</td>\n",
       "      <td>20240825</td>\n",
       "      <td>4</td>\n",
       "      <td>UX</td>\n",
       "      <td>...</td>\n",
       "      <td>A NIVEL NACIONAL</td>\n",
       "      <td>TR</td>\n",
       "      <td>TURKEY</td>\n",
       "      <td>IST</td>\n",
       "      <td>ISTANBUL</td>\n",
       "      <td>AEREA Y POSTAL EX-IAAC</td>\n",
       "      <td>BULTOS                                        ...</td>\n",
       "      <td>AIR EUROPA LINEAS AEREAS S.A. SUCURSAL DEL PERU</td>\n",
       "      <td>10</td>\n",
       "      <td>NUEVO/BUENO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>235</td>\n",
       "      <td>135859</td>\n",
       "      <td>20240903</td>\n",
       "      <td>4</td>\n",
       "      <td>20606352825</td>\n",
       "      <td>2M DIESEL S.A.C.</td>\n",
       "      <td>14</td>\n",
       "      <td>20240825</td>\n",
       "      <td>4</td>\n",
       "      <td>UX</td>\n",
       "      <td>...</td>\n",
       "      <td>A NIVEL NACIONAL</td>\n",
       "      <td>TR</td>\n",
       "      <td>TURKEY</td>\n",
       "      <td>IST</td>\n",
       "      <td>ISTANBUL</td>\n",
       "      <td>AEREA Y POSTAL EX-IAAC</td>\n",
       "      <td>BULTOS                                        ...</td>\n",
       "      <td>AIR EUROPA LINEAS AEREAS S.A. SUCURSAL DEL PERU</td>\n",
       "      <td>10</td>\n",
       "      <td>NUEVO/BUENO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>235</td>\n",
       "      <td>137787</td>\n",
       "      <td>20240906</td>\n",
       "      <td>4</td>\n",
       "      <td>20503101913</td>\n",
       "      <td>A &amp; N PROYECTOS S.A.C. - A &amp; N S.A.C.</td>\n",
       "      <td>3728</td>\n",
       "      <td>20240907</td>\n",
       "      <td>4</td>\n",
       "      <td>AF</td>\n",
       "      <td>...</td>\n",
       "      <td>No mencionado</td>\n",
       "      <td>ES</td>\n",
       "      <td>SPAIN</td>\n",
       "      <td>BCN</td>\n",
       "      <td>BARCELONA</td>\n",
       "      <td>AEREA Y POSTAL EX-IAAC</td>\n",
       "      <td>BULTOS                                        ...</td>\n",
       "      <td>SOCIETE AIR FRANCE SUCURSAL EN EL PERU</td>\n",
       "      <td>10</td>\n",
       "      <td>NUEVO/BUENO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>235</td>\n",
       "      <td>137787</td>\n",
       "      <td>20240906</td>\n",
       "      <td>4</td>\n",
       "      <td>20503101913</td>\n",
       "      <td>A &amp; N PROYECTOS S.A.C. - A &amp; N S.A.C.</td>\n",
       "      <td>3728</td>\n",
       "      <td>20240907</td>\n",
       "      <td>4</td>\n",
       "      <td>AF</td>\n",
       "      <td>...</td>\n",
       "      <td>No mencionado</td>\n",
       "      <td>ES</td>\n",
       "      <td>SPAIN</td>\n",
       "      <td>BCN</td>\n",
       "      <td>BARCELONA</td>\n",
       "      <td>AEREA Y POSTAL EX-IAAC</td>\n",
       "      <td>BULTOS                                        ...</td>\n",
       "      <td>SOCIETE AIR FRANCE SUCURSAL EN EL PERU</td>\n",
       "      <td>10</td>\n",
       "      <td>NUEVO/BUENO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>235</td>\n",
       "      <td>137787</td>\n",
       "      <td>20240906</td>\n",
       "      <td>4</td>\n",
       "      <td>20503101913</td>\n",
       "      <td>A &amp; N PROYECTOS S.A.C. - A &amp; N S.A.C.</td>\n",
       "      <td>3728</td>\n",
       "      <td>20240907</td>\n",
       "      <td>4</td>\n",
       "      <td>AF</td>\n",
       "      <td>...</td>\n",
       "      <td>No mencionado</td>\n",
       "      <td>ES</td>\n",
       "      <td>SPAIN</td>\n",
       "      <td>BCN</td>\n",
       "      <td>BARCELONA</td>\n",
       "      <td>AEREA Y POSTAL EX-IAAC</td>\n",
       "      <td>BULTOS                                        ...</td>\n",
       "      <td>SOCIETE AIR FRANCE SUCURSAL EN EL PERU</td>\n",
       "      <td>10</td>\n",
       "      <td>NUEVO/BUENO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CODI_ADUAN  NUME_CORRE  FECH_INGSI TIPO_DOCUM   LIBR_TRIBU  \\\n",
       "0         235      135859    20240903          4  20606352825   \n",
       "1         235      135859    20240903          4  20606352825   \n",
       "2         235      137787    20240906          4  20503101913   \n",
       "3         235      137787    20240906          4  20503101913   \n",
       "4         235      137787    20240906          4  20503101913   \n",
       "\n",
       "                                 DNOMBRE  CODI_AGENT  FECH_LLEGA  VIA_TRANSP  \\\n",
       "0                       2M DIESEL S.A.C.          14    20240825           4   \n",
       "1                       2M DIESEL S.A.C.          14    20240825           4   \n",
       "2  A & N PROYECTOS S.A.C. - A & N S.A.C.        3728    20240907           4   \n",
       "3  A & N PROYECTOS S.A.C. - A & N S.A.C.        3728    20240907           4   \n",
       "4  A & N PROYECTOS S.A.C. - A & N S.A.C.        3728    20240907           4   \n",
       "\n",
       "  EMPR_TRANS  ...  Jurisdiccion_Almacen  Cpais   Dpais Cpuerto    Dpuerto  \\\n",
       "0         UX  ...      A NIVEL NACIONAL     TR  TURKEY     IST   ISTANBUL   \n",
       "1         UX  ...      A NIVEL NACIONAL     TR  TURKEY     IST   ISTANBUL   \n",
       "2         AF  ...         No mencionado     ES   SPAIN     BCN  BARCELONA   \n",
       "3         AF  ...         No mencionado     ES   SPAIN     BCN  BARCELONA   \n",
       "4         AF  ...         No mencionado     ES   SPAIN     BCN  BARCELONA   \n",
       "\n",
       "       Descripcion_Aduana                                        Clase_Bulto  \\\n",
       "0  AEREA Y POSTAL EX-IAAC  BULTOS                                        ...   \n",
       "1  AEREA Y POSTAL EX-IAAC  BULTOS                                        ...   \n",
       "2  AEREA Y POSTAL EX-IAAC  BULTOS                                        ...   \n",
       "3  AEREA Y POSTAL EX-IAAC  BULTOS                                        ...   \n",
       "4  AEREA Y POSTAL EX-IAAC  BULTOS                                        ...   \n",
       "\n",
       "                                      Razon Social Codigo Estado_Mercancia  \n",
       "0  AIR EUROPA LINEAS AEREAS S.A. SUCURSAL DEL PERU     10      NUEVO/BUENO  \n",
       "1  AIR EUROPA LINEAS AEREAS S.A. SUCURSAL DEL PERU     10      NUEVO/BUENO  \n",
       "2           SOCIETE AIR FRANCE SUCURSAL EN EL PERU     10      NUEVO/BUENO  \n",
       "3           SOCIETE AIR FRANCE SUCURSAL EN EL PERU     10      NUEVO/BUENO  \n",
       "4           SOCIETE AIR FRANCE SUCURSAL EN EL PERU     10      NUEVO/BUENO  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def transformar_valor(valor):\n",
    "    # Verificar si es un número flotante y termina en .0\n",
    "    if isinstance(valor, float) and valor.is_integer():\n",
    "        # Convertir a entero, luego a string de longitud 4 con ceros a la izquierda\n",
    "        return f\"{int(valor):04d}\"\n",
    "    # Verificar si es un string que termina con .0\n",
    "    elif isinstance(valor, str) and valor.endswith('.0') and valor[:-2].isdigit():\n",
    "        # Convertir a entero, luego a string de longitud 4 con ceros a la izquierda\n",
    "        return f\"{int(float(valor)) :04d}\"\n",
    "    # Dejar los valores no numéricos tal cual\n",
    "    return str(valor)  # Convertir todo lo demás a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aver = df_aver.loc[~df_aver['EMPR_TRANS'].isin(['nan'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empres = pd.read_fwf(\"LinAereasManif.txt\", widths=[7, 71, 7, 51, 15, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empres\n",
    "df_empres['Codigo'] = df_empres['Codigo'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empres = df_empres[['Codigo','Descripcion']]\n",
    "df_empres.rename(columns={'Descripcion':'Razon Social'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Codigo</th>\n",
       "      <th>Razon Social</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0A</td>\n",
       "      <td>SERVICIOS AEREOS COLIBRI S.A.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0B</td>\n",
       "      <td>AERO CONDOR S.A.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0C</td>\n",
       "      <td>LAN PERU S.A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0D</td>\n",
       "      <td>AVIACION LIDER S.A.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0E</td>\n",
       "      <td>TRANS AMERICAN AIR LINES S.A.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>XX</td>\n",
       "      <td>TAM LINEAS AEREAS S.A.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>YU</td>\n",
       "      <td>AEROLINEAS DOMINICANAS S.A. (DOMINAIR)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>ZA</td>\n",
       "      <td>BAY AIR CARGO SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>ZS</td>\n",
       "      <td>ANGLO AMERICAN CORPORATION OF SOUTH AFRICA LTD.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>ZZ</td>\n",
       "      <td>OTRAS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Codigo                                     Razon Social\n",
       "0       0A                    SERVICIOS AEREOS COLIBRI S.A.\n",
       "1       0B                                 AERO CONDOR S.A.\n",
       "2       0C                                     LAN PERU S.A\n",
       "3       0D                              AVIACION LIDER S.A.\n",
       "4       0E                    TRANS AMERICAN AIR LINES S.A.\n",
       "..     ...                                              ...\n",
       "128     XX                           TAM LINEAS AEREAS S.A.\n",
       "129     YU           AEROLINEAS DOMINICANAS S.A. (DOMINAIR)\n",
       "130     ZA                                 BAY AIR CARGO SA\n",
       "131     ZS  ANGLO AMERICAN CORPORATION OF SOUTH AFRICA LTD.\n",
       "132     ZZ                                            OTRAS\n",
       "\n",
       "[133 rows x 2 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_empres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empres_2 = pd.read_fwf(\"EmpNacional.txt\",widths=[7, 82,15, 51, 15, 50])\n",
    "df_empres_2.drop_duplicates(subset='Codigo',inplace=True)\n",
    "df_empres_2['Razon Social'] = df_empres_2['Razon Social'].str.replace(r'\\bRUC\\b|\\d+', '', regex=True).str.strip()\n",
    "df_empres_2['Codigo'] = df_empres_2['Codigo'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empres_2 = df_empres_2[['Codigo',\"Razon Social\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_empres_2.drop(2,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Codigo</th>\n",
       "      <th>Razon Social</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nan</td>\n",
       "      <td>INTEROCEANICA POMA (PERMISO OCASIONAL)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000</td>\n",
       "      <td>TRANSPORTES EMELINA MAGDALENA ROMERO RIVAS EIRL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001</td>\n",
       "      <td>AMERICA INTERNACIONAL TOURS S.A. AMINTOURS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002</td>\n",
       "      <td>EXPRESO INTERNACIONAL ORMEÑO S.A.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0003</td>\n",
       "      <td>TRANSPORTES VILLANUEVA S.A      (TRANVINSA)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5072</th>\n",
       "      <td>9960</td>\n",
       "      <td>LUPACA RAMOS WILFREDO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5073</th>\n",
       "      <td>9993</td>\n",
       "      <td>PARTICULAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5075</th>\n",
       "      <td>9997</td>\n",
       "      <td>TRABAJOS MARITIMOS S.A.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5076</th>\n",
       "      <td>9998</td>\n",
       "      <td>PROVISIONAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5080</th>\n",
       "      <td>9999</td>\n",
       "      <td>PROPIOS MEDIOS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4812 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Codigo                                     Razon Social\n",
       "0       nan           INTEROCEANICA POMA (PERMISO OCASIONAL)\n",
       "3      0000  TRANSPORTES EMELINA MAGDALENA ROMERO RIVAS EIRL\n",
       "4      0001       AMERICA INTERNACIONAL TOURS S.A. AMINTOURS\n",
       "6      0002                EXPRESO INTERNACIONAL ORMEÑO S.A.\n",
       "8      0003      TRANSPORTES VILLANUEVA S.A      (TRANVINSA)\n",
       "...     ...                                              ...\n",
       "5072   9960                            LUPACA RAMOS WILFREDO\n",
       "5073   9993                                       PARTICULAR\n",
       "5075   9997                          TRABAJOS MARITIMOS S.A.\n",
       "5076   9998                                      PROVISIONAL\n",
       "5080   9999                                   PROPIOS MEDIOS\n",
       "\n",
       "[4812 rows x 2 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_empres_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_empres_3 = pd.read_fwf(\"AgenMar.txt\",widths=[7, 71,15, 51, 15, 50])\n",
    "df_empres_3.drop_duplicates(subset='Codigo',inplace=True)\n",
    "df_empres_3['Agente_Maritimo'] = df_empres_3['Agente_Maritimo'].str.replace(r'\\bRUC\\b|\\d+', '', regex=True).str.strip()\n",
    "df_empres_3['Codigo'] = df_empres_3['Codigo'].astype(str)\n",
    "df_empres_3.rename(columns={\"Agente_Maritimo\":\"Razon Social\"},inplace=True)\n",
    "df_empres_3 = df_empres_3[['Codigo','Razon Social']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empres_3['Codigo'] = df_empres_3['Codigo'].apply(lambda x: f\"{int(x):04d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Codigo</th>\n",
       "      <th>Razon Social</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0019</td>\n",
       "      <td>ABRAHAM WOLL DAVILA S.A.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0028</td>\n",
       "      <td>SANTA SOFIA PUERTOS S.A.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0037</td>\n",
       "      <td>AGENCIA MARITIMA COLUMBIA DEL PERU S.A.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0046</td>\n",
       "      <td>AGENCIA MARITIMA SAN CARLOS S.A.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0055</td>\n",
       "      <td>MAR PISCO S R LTDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>9957</td>\n",
       "      <td>AGENCIA MARITIMA FULL SEAS S.A.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>9966</td>\n",
       "      <td>LATINOAMERICANA INVERSIONES MARITIMAS S.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>9975</td>\n",
       "      <td>AGENCIA MARITIMA FULL SHIPPING SERVICE S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>9984</td>\n",
       "      <td>AGENCIA MARITIMA MARKO BUSONICH S.R.L.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>9993</td>\n",
       "      <td>OTROS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Codigo                              Razon Social\n",
       "0     0019                  ABRAHAM WOLL DAVILA S.A.\n",
       "1     0028                  SANTA SOFIA PUERTOS S.A.\n",
       "3     0037   AGENCIA MARITIMA COLUMBIA DEL PERU S.A.\n",
       "4     0046          AGENCIA MARITIMA SAN CARLOS S.A.\n",
       "5     0055                        MAR PISCO S R LTDA\n",
       "..     ...                                       ...\n",
       "520   9957           AGENCIA MARITIMA FULL SEAS S.A.\n",
       "521   9966  LATINOAMERICANA INVERSIONES MARITIMAS S.\n",
       "523   9975  AGENCIA MARITIMA FULL SHIPPING SERVICE S\n",
       "524   9984    AGENCIA MARITIMA MARKO BUSONICH S.R.L.\n",
       "527   9993                                     OTROS\n",
       "\n",
       "[277 rows x 2 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_empres_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {\n",
    "    4: df_empres,\n",
    "    7: df_empres_2,\n",
    "    1: df_empres_3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:34<00:00,  1.96it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "chunk_size = 100000  # Ajusta este valor según la memoria disponible\n",
    "num_chunks = len(df_aver) // chunk_size + 1\n",
    "\n",
    "merged_chunks = []\n",
    "\n",
    "for i in tqdm(range(num_chunks)):\n",
    "    # Seleccionar un fragmento del DataFrame\n",
    "    chunk = df_aver.iloc[i * chunk_size:(i + 1) * chunk_size]\n",
    "\n",
    "    # Filtrar y hacer merge por cada valor de `via_transporte` en el fragmento\n",
    "    for transporte, df_empresas in dataframes.items():\n",
    "        df_filtered = chunk[chunk['VIA_TRANSP'] == transporte]\n",
    "        merged_chunk = pd.merge(df_filtered, df_empresas, how='left', left_on='EMPR_TRANS',right_on='Codigo')\n",
    "        merged_chunks.append(merged_chunk)\n",
    "\n",
    "# Combina solo los fragmentos procesados\n",
    "df_final = pd.concat(merged_chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['Razon Social'] = df_final['Razon Social'].fillna(\"No mencionado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6675814, 43)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CODI_ADUAN', 'NUME_CORRE', 'FECH_INGSI', 'TIPO_DOCUM', 'LIBR_TRIBU',\n",
       "       'DNOMBRE', 'CODI_AGENT', 'FECH_LLEGA', 'VIA_TRANSP', 'EMPR_TRANS',\n",
       "       'CODI_ALMA', 'FECH_RECEP', 'PAIS_ORIGE', 'PAIS_ADQUI', 'PUER_EMBAR',\n",
       "       'FECH_EMBAR', 'NUME_SERIE', 'DESC_COMER', 'DESC_MATCO', 'DESC_USOAP',\n",
       "       'DESC_FOPRE', 'DESC_OTROS', 'FLE_DOLAR', 'SEG_DOLAR', 'PESO_NETO',\n",
       "       'PESO_BRUTO', 'UNID_FIQTY', 'UNID_FIDES', 'QUNICOM', 'TUNICOM',\n",
       "       'SEST_MERCA', 'CANT_BULTO', 'CLASE', 'Razon_Social_Almacen',\n",
       "       'Jurisdiccion_Almacen', 'Cpais', 'Dpais', 'Cpuerto', 'Dpuerto',\n",
       "       'Descripcion_Aduana', 'Clase_Bulto', 'Codigo', 'Razon Social'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando registros: 100%|██████████| 7141397/7141397 [2:39:01<00:00, 748.43it/s]   \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for index, row in tqdm(df_importaciones.iterrows(),total=len(df_importaciones), desc=\"Procesando registros\"):\n",
    "        # Revisa la longitud de las columnas y valores para identificar el problema\n",
    "        columnas = [\n",
    "            'CODI_ADUAN', 'ANO_PRESE', 'NUME_CORRE', 'FECH_INGSI', 'TIPO_DOCUM', 'LIBR_TRIBU',\n",
    "            'DNOMBRE', 'CODI_AGENT', 'FECH_LLEGA', 'VIA_TRANSP', 'EMPR_TRANS', 'CODI_ALMA',\n",
    "            'CADU_MANIF', 'FECH_MANIF', 'NUME_MANIF', 'FECH_RECEP', 'FECH_CANCE', 'TIPO_CANCE',\n",
    "            'BANC_CANCE', 'CODI_ENFIN', 'DK', 'PAIS_ORIGE', 'PAIS_ADQUI', 'PUER_EMBAR',\n",
    "            'NUME_SERIE', 'PART_NANDI', 'DESC_COMER', 'DESC_MATCO', 'DESC_USOAP', 'DESC_FOPRE',\n",
    "            'DESC_OTROS', 'FOB_DOLPOL', 'FLE_DOLAR', 'SEG_DOLAR', 'PESO_NETO', 'PESO_BRUTO',\n",
    "            'UNID_FIQTY', 'UNID_FIDES', 'QUNICOM', 'TUNICOM', 'SEST_MERCA', 'ADV_DOLAR',\n",
    "            'IGV_DOLAR', 'ISC_DOLAR', 'IPM_DOLAR', 'DES_DOLAR', 'IPA_DOLAR', 'SAD_DOLAR',\n",
    "            'DER_ADUM', 'COMM', 'FMOD', 'CANT_BULTO', 'CLASE', 'TRAT_PREFE', 'TIPO_TRAT',\n",
    "            'CODI_LIBER', 'IMPR_RELIQ'\n",
    "        ]\n",
    "        \n",
    "        valores = [\n",
    "            row['CODI_ADUAN'], row['ANO_PRESE'], row['NUME_CORRE'], row['FECH_INGSI'],\n",
    "            row['TIPO_DOCUM'], row['LIBR_TRIBU'], row['DNOMBRE'], row['CODI_AGENT'],\n",
    "            row['FECH_LLEGA'], row['VIA_TRANSP'], row['EMPR_TRANS'], row['CODI_ALMA'],\n",
    "            row['CADU_MANIF'], row['FECH_MANIF'], row['NUME_MANIF'], row['FECH_RECEP'],\n",
    "            row['FECH_CANCE'], row['TIPO_CANCE'], row['BANC_CANCE'], row['CODI_ENFIN'],\n",
    "            row['DK'], row['PAIS_ORIGE'], row['PAIS_ADQUI'], row['PUER_EMBAR'],\n",
    "            row['NUME_SERIE'], row['PART_NANDI'], row['DESC_COMER'], row['DESC_MATCO'],\n",
    "            row['DESC_USOAP'], row['DESC_FOPRE'], row['DESC_OTROS'], row['FOB_DOLPOL'],\n",
    "            row['FLE_DOLAR'], row['SEG_DOLAR'], row['PESO_NETO'], row['PESO_BRUTO'],\n",
    "            row['UNID_FIQTY'], row['UNID_FIDES'], row['QUNICOM'], row['TUNICOM'],\n",
    "            row['SEST_MERCA'], row['ADV_DOLAR'], row['IGV_DOLAR'], row['ISC_DOLAR'],\n",
    "            row['IPM_DOLAR'], row['DES_DOLAR'], row['IPA_DOLAR'], row['SAD_DOLAR'],\n",
    "            row['DER_ADUM'], row['COMM'], row['FMOD'], row['CANT_BULTO'], row['CLASE'],\n",
    "            row['TRAT_PREFE'], row['TIPO_TRAT'], row['CODI_LIBER'], row['IMPR_RELIQ']\n",
    "        ]\n",
    "        \n",
    "        if len(columnas) != len(valores):\n",
    "            print(f\"Discrepancia: {len(columnas)} columnas, {len(valores)} valores\")\n",
    "            break  \n",
    "\n",
    "        try:\n",
    "            cursor.execute(f\"\"\"\n",
    "                INSERT INTO ImportacionesA (\n",
    "                    {\", \".join(columnas)}\n",
    "                ) VALUES ({\", \".join([\"?\" for _ in columnas])})\n",
    "            \"\"\", valores)\n",
    "        except Exception as e:\n",
    "            print(f\"Error al insertar el registro en el índice {index}: {e}\")\n",
    "            for col, val in zip(columnas, valores):\n",
    "                try:\n",
    "                    cursor.execute(f\"SELECT CAST(? AS VARCHAR(255))\", (val,))\n",
    "                except Exception as col_error:\n",
    "                    print(f\"Problema en la columna '{col}' con valor '{val}': {col_error}\")\n",
    "                    break  \n",
    "\n",
    "    conn.commit()\n",
    "except ValueError as e:\n",
    "    print(\"Error general al procesar los registros:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importaciones B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mb = pd.read_csv('ImportacionB.csv',encoding='utf-8', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CODI_ADUAN', 'ANO_PRESE', 'NUME_CORRE', 'NUME_SECUP', 'NUME_SECUF',\n",
       "       'FECH_INGSI', 'CODI_PROVE', 'NOMB_PROVE', 'PART_NANDI', 'NUME_ITEM',\n",
       "       'VFOB_ITEM', 'NOMB_COMER', 'MARC_COMER', 'MODE_MERCD', 'CANT_MERCD',\n",
       "       'UNID_MERCD', 'CARA_TIPO', 'PAIS_ORIGE', 'ARO_ANO', 'ESTA_MERCD',\n",
       "       'VFOB_UNITA', 'TERM_TRANS', 'LUGA_TRANS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Campos con nan\n",
      "NOMB_COMER 27498\n",
      "MARC_COMER 69\n",
      "MODE_MERCD 1621\n",
      "CARA_TIPO 8625\n",
      "PAIS_ORIGE 2\n",
      "ARO_ANO 1893\n"
     ]
    }
   ],
   "source": [
    "print(\"Campos con nan\")\n",
    "for c in df_mb.columns:\n",
    "    x=sum(df_mb[c].isna())\n",
    "    if x!=0:\n",
    "        print(c, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos duplicados y reemplazamos nan (ocasionan problemas al momento de subir la base)\n",
    "df_mb=df_mb.drop_duplicates()\n",
    "df_mb=df_mb.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODI_ADUAN</th>\n",
       "      <th>ANO_PRESE</th>\n",
       "      <th>NUME_CORRE</th>\n",
       "      <th>NUME_SECUP</th>\n",
       "      <th>NUME_SECUF</th>\n",
       "      <th>FECH_INGSI</th>\n",
       "      <th>CODI_PROVE</th>\n",
       "      <th>NOMB_PROVE</th>\n",
       "      <th>PART_NANDI</th>\n",
       "      <th>NUME_ITEM</th>\n",
       "      <th>...</th>\n",
       "      <th>MODE_MERCD</th>\n",
       "      <th>CANT_MERCD</th>\n",
       "      <th>UNID_MERCD</th>\n",
       "      <th>CARA_TIPO</th>\n",
       "      <th>PAIS_ORIGE</th>\n",
       "      <th>ARO_ANO</th>\n",
       "      <th>ESTA_MERCD</th>\n",
       "      <th>VFOB_UNITA</th>\n",
       "      <th>TERM_TRANS</th>\n",
       "      <th>LUGA_TRANS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20240904</td>\n",
       "      <td>No Disponi</td>\n",
       "      <td>No Disponible</td>\n",
       "      <td>8430490000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>S/M</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U</td>\n",
       "      <td>DE PERFORACION PETROLERA ,USADO,DESARMADO,REFE...</td>\n",
       "      <td>IT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>6856211.860</td>\n",
       "      <td>FCA</td>\n",
       "      <td>HUAQUILLAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20240904</td>\n",
       "      <td>No Disponi</td>\n",
       "      <td>No Disponible</td>\n",
       "      <td>8429510000</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>980 G</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U</td>\n",
       "      <td>MONTACARGA (CARGADOR FRONTAL) *9CM01332*</td>\n",
       "      <td>US</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>106425.000</td>\n",
       "      <td>FCA</td>\n",
       "      <td>HUAQUILLAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20240904</td>\n",
       "      <td>No Disponi</td>\n",
       "      <td>No Disponible</td>\n",
       "      <td>8431490000</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>S/M</td>\n",
       "      <td>2.0</td>\n",
       "      <td>U</td>\n",
       "      <td>INCLUYE ACCESORIOS Y PARTES PARA SU NORMAL FUN...</td>\n",
       "      <td>US</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>4025.135</td>\n",
       "      <td>FCA</td>\n",
       "      <td>HUAQUILLAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20240904</td>\n",
       "      <td>No Disponi</td>\n",
       "      <td>No Disponible</td>\n",
       "      <td>8430490000</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>S/M</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U</td>\n",
       "      <td>ONE NEW POWER CONTROL ROOM-SCR FOR HH220</td>\n",
       "      <td>NL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>835058.180</td>\n",
       "      <td>FCA</td>\n",
       "      <td>HUAQUILLAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>20240904</td>\n",
       "      <td>No Disponi</td>\n",
       "      <td>No Disponible</td>\n",
       "      <td>8430490000</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9T1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U</td>\n",
       "      <td>MUD PUMPS 9T1000DC-9T1000-155B</td>\n",
       "      <td>IT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>451023.260</td>\n",
       "      <td>FCA</td>\n",
       "      <td>HUAQUILLAS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CODI_ADUAN  ANO_PRESE  NUME_CORRE  NUME_SECUP  NUME_SECUF  FECH_INGSI  \\\n",
       "0          19         24          18           1           1    20240904   \n",
       "1          19         24          18           1           2    20240904   \n",
       "2          19         24          18           1           2    20240904   \n",
       "3          19         24          18           1           3    20240904   \n",
       "4          19         24          18           1           4    20240904   \n",
       "\n",
       "   CODI_PROVE     NOMB_PROVE  PART_NANDI  NUME_ITEM  ...  MODE_MERCD  \\\n",
       "0  No Disponi  No Disponible  8430490000          1  ...         S/M   \n",
       "1  No Disponi  No Disponible  8429510000          2  ...       980 G   \n",
       "2  No Disponi  No Disponible  8431490000          3  ...         S/M   \n",
       "3  No Disponi  No Disponible  8430490000          4  ...         S/M   \n",
       "4  No Disponi  No Disponible  8430490000          5  ...      9T1000   \n",
       "\n",
       "  CANT_MERCD UNID_MERCD                                          CARA_TIPO  \\\n",
       "0        1.0          U  DE PERFORACION PETROLERA ,USADO,DESARMADO,REFE...   \n",
       "1        1.0          U           MONTACARGA (CARGADOR FRONTAL) *9CM01332*   \n",
       "2        2.0          U  INCLUYE ACCESORIOS Y PARTES PARA SU NORMAL FUN...   \n",
       "3        1.0          U           ONE NEW POWER CONTROL ROOM-SCR FOR HH220   \n",
       "4        1.0          U                     MUD PUMPS 9T1000DC-9T1000-155B   \n",
       "\n",
       "   PAIS_ORIGE ARO_ANO ESTA_MERCD   VFOB_UNITA  TERM_TRANS  LUGA_TRANS  \n",
       "0          IT     0.0         22  6856211.860         FCA  HUAQUILLAS  \n",
       "1          US     0.0         20   106425.000         FCA  HUAQUILLAS  \n",
       "2          US     0.0         20     4025.135         FCA  HUAQUILLAS  \n",
       "3          NL     0.0         20   835058.180         FCA  HUAQUILLAS  \n",
       "4          IT     0.0         20   451023.260         FCA  HUAQUILLAS  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando registros:   0%|          | 0/2543947 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando registros: 100%|██████████| 2543947/2543947 [11:36<00:00, 3650.38it/s] \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for index, row in tqdm(df_mb.iterrows(), total=len(df_mb), desc= \"Procesando registros\"):\n",
    "        # Revisa la longitud de las columnas y valores para identificar el problema\n",
    "        columnas = [\n",
    "           'CODI_ADUAN', 'ANO_PRESE', 'NUME_CORRE', 'NUME_SECUP',\n",
    "           'FECH_INGSI', 'CODI_PROVE', 'NOMB_PROVE', 'PART_NANDI', 'NUME_ITEM',\n",
    "           'VFOB_ITEM', 'NOMB_COMER', 'MARC_COMER', 'MODE_MERCD', 'CANT_MERCD',\n",
    "           'UNID_MERCD', 'CARA_TIPO', 'PAIS_ORIGE', 'ARO_ANO', 'ESTA_MERCD',\n",
    "           'VFOB_UNITA'\n",
    "        ]\n",
    "        \n",
    "        valores = [\n",
    "            row['CODI_ADUAN'], row['ANO_PRESE'], row['NUME_CORRE'],\n",
    "            row['NUME_SECUF'], row['FECH_INGSI'], row['CODI_PROVE'], row['NOMB_PROVE'],\n",
    "            row['PART_NANDI'], row['NUME_ITEM'], row['VFOB_ITEM'], row['NOMB_COMER'],\n",
    "            row['MARC_COMER'], row['MODE_MERCD'], row['CANT_MERCD'], row['UNID_MERCD'],\n",
    "            row['CARA_TIPO'], row['PAIS_ORIGE'], row['ARO_ANO'], row['ESTA_MERCD'],\n",
    "            row['VFOB_UNITA']\n",
    "]\n",
    "\n",
    "        \n",
    "        # Asegúrate de que las longitudes coincidan\n",
    "        if len(columnas) != len(valores):\n",
    "            print(f\"Discrepancia: {len(columnas)} columnas, {len(valores)} valores\")\n",
    "            break  \n",
    "\n",
    "        try:\n",
    "            # Inserta el registro en la base de datos\n",
    "            cursor.execute(f\"\"\"\n",
    "                INSERT INTO ImportacionB (\n",
    "                    {\", \".join(columnas)}\n",
    "                ) VALUES ({\", \".join([\"?\" for _ in columnas])})\n",
    "            \"\"\", valores)\n",
    "        except Exception as e:\n",
    "            # Imprime el índice del registro, la columna y el valor problemático\n",
    "            print(f\"Error al insertar el registro en el índice {index}: {e}\")\n",
    "            for col, val in zip(columnas, valores):\n",
    "                try:\n",
    "                    # Prueba insertar cada campo individualmente para aislar el valor problemático\n",
    "                    cursor.execute(f\"SELECT CAST(? AS VARCHAR(255))\", (val,))\n",
    "                except Exception as col_error:\n",
    "                    print(f\"Problema en la columna '{col}' con valor '{val}': {col_error}\")\n",
    "                    break  # Sal del loop una vez encontrado el valor problemático\n",
    "\n",
    "    conn.commit()\n",
    "except ValueError as e:\n",
    "    print(\"Error general al procesar los registros:\", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gonza\\AppData\\Local\\Temp\\ipykernel_16820\\3645491519.py:1: DtypeWarning: Columns (18,24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_exp = pd.read_csv('Exportacion.csv',encoding='utf-8', sep=';')\n"
     ]
    }
   ],
   "source": [
    "df_exp = pd.read_csv('Exportacion.csv',encoding='utf-8', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CADU', 'FANO', 'NDCL', 'FNUM', 'FEMB', 'FECH_RECEP', 'NDCLREG', 'FREG',\n",
       "       'FANOREG', 'CAGE', 'TDOC', 'NDOC', 'DNOMBRE', 'CPAIDES', 'CPUEDES',\n",
       "       'CVIATRA', 'CUNITRA', 'CEMPTRA', 'DMAT', 'NCON', 'CENTFIN', 'CALM',\n",
       "       'DNOMPRO', 'DDIRPRO', 'DK', 'DK2', 'NSER', 'PART_NANDI', 'DCOM',\n",
       "       'DMER2', 'DMER3', 'DMER4', 'DMER5', 'CEST', 'VFOBSERDOL', 'VPESNET',\n",
       "       'VPESBRU', 'QUNIFIS', 'TUNIFIS', 'QUNICOM', 'TUNICOM', 'UBIGEO',\n",
       "       'DNOMCON', 'DDIRCON'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exp.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
